{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import yaml\n",
    "from run_experiment import run_exp\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T12:05:56.449434Z",
     "start_time": "2023-08-17T12:05:56.433688Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def plot_comparison(a, b, c):\n",
    "    # Convert to NumPy arrays\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    # Calculate mean and standard deviation for a and b\n",
    "    a_mean = a.mean(axis=0)\n",
    "    a_std = a.std(axis=0)\n",
    "    b_mean = b.mean(axis=0)\n",
    "    b_std = b.std(axis=0)\n",
    "    c_mean = c.mean(axis=0)\n",
    "    c_std = c.std(axis=0)\n",
    "\n",
    "\n",
    "    # Plot mean lines\n",
    "    plt.plot(a_mean, label='baseline', color = 'green')\n",
    "    plt.text(len(a_mean) - 1, a_mean[-1], f'{a_mean[-1]:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "    # Shade areas for standard deviations\n",
    "    plt.fill_between(range(len(a_mean)), a_mean - a_std, a_mean + a_std, alpha=0.2)\n",
    "\n",
    "\n",
    "\n",
    "    if len(b[0]) != 0 :\n",
    "        plt.plot(b_mean, label='model-based LinUCB', color = 'blue')\n",
    "        plt.text(len(b_mean) - 1, b_mean[-1], f'{b_mean[-1]:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "        plt.fill_between(range(len(b_mean)), b_mean - b_std, b_mean + b_std, alpha=0.2)\n",
    "\n",
    "\n",
    "    if len(c[0]) != 0 :\n",
    "        plt.plot(c_mean, label='online model-based LinUCB', color = 'yellow')\n",
    "        plt.text(len(c_mean) - 1, c_mean[-1], f'{c_mean[-1]:.1f}', verticalalignment='bottom', horizontalalignment='right')\n",
    "        plt.fill_between(range(len(c_mean)), c_mean - c_std, c_mean + c_std, alpha=0.2)\n",
    "\n",
    "    plt.xlabel('round t')\n",
    "    plt.ylabel('cummulative regret')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T12:05:56.488404Z",
     "start_time": "2023-08-17T12:05:56.447032Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rounds': 20, 'num_node': 10, 'train_rounds': 1000, 'online_train_rounds': 800, 'T': 300, 'test_rounds': 3000, 'num_data': 0, 'alpha': 1, 'given_data': False}\n",
      "Empty DataFrame\n",
      "Columns: [x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, Y]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1/20 [22:15<7:02:51, 1335.32s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig.yaml\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m      2\u001B[0m     config \u001B[38;5;241m=\u001B[39m yaml\u001B[38;5;241m.\u001B[39mload(file, Loader\u001B[38;5;241m=\u001B[39myaml\u001B[38;5;241m.\u001B[39mFullLoader)\n\u001B[0;32m----> 3\u001B[0m a,b,c \u001B[38;5;241m=\u001B[39m \u001B[43mrun_exp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject19/CAUSAL/causal_bandit/model/run_experiment.py:60\u001B[0m, in \u001B[0;36mrun_exp\u001B[0;34m(config)\u001B[0m\n\u001B[1;32m     57\u001B[0m test \u001B[38;5;241m=\u001B[39m Tester(env, algo, bmb, T, online_train_rounds)\n\u001B[1;32m     59\u001B[0m test\u001B[38;5;241m.\u001B[39mload_dic(dic_path\u001B[38;5;241m=\u001B[39mdic_path)\n\u001B[0;32m---> 60\u001B[0m \u001B[43mtest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_rounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompare\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monline_update\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgiven_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mgiven_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m baseline_regret_list\u001B[38;5;241m.\u001B[39mappend(test\u001B[38;5;241m.\u001B[39mbaseline_regret_list)\n\u001B[1;32m     62\u001B[0m mb_regret_list\u001B[38;5;241m.\u001B[39mappend(test\u001B[38;5;241m.\u001B[39mregret_list)\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject19/CAUSAL/causal_bandit/model/Train.py:140\u001B[0m, in \u001B[0;36mTester.test\u001B[0;34m(self, n_rounds, compare, online_update, given_data, show_progress)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mlearn()\n\u001B[1;32m    139\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39monline_algo)\n\u001B[0;32m--> 140\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_rounds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m online_context_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    143\u001B[0m online_intervened_list \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject19/CAUSAL/causal_bandit/model/Train.py:26\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, n_rounds, show_progress)\u001B[0m\n\u001B[1;32m     24\u001B[0m     iterable \u001B[38;5;241m=\u001B[39m tqdm(iterable)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m---> 26\u001B[0m     context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m#transfrom dic to list\u001B[39;00m\n\u001B[1;32m     28\u001B[0m     context_list \u001B[38;5;241m=\u001B[39m rerank_and_transform(context)\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject19/CAUSAL/causal_bandit/model/learn_bayesian_network.py:42\u001B[0m, in \u001B[0;36mBayesian_Model_Bandit.generate_context\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_context\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimulate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m  \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto_dict()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pgmpy/models/BayesianNetwork.py:1303\u001B[0m, in \u001B[0;36mBayesianNetwork.simulate\u001B[0;34m(self, n_samples, do, evidence, virtual_evidence, virtual_intervention, include_latents, partial_samples, seed, show_progress)\u001B[0m\n\u001B[1;32m   1301\u001B[0m \u001B[38;5;66;03m# Step 3: If no evidence do a forward sampling\u001B[39;00m\n\u001B[1;32m   1302\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(evidence) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1303\u001B[0m     samples \u001B[38;5;241m=\u001B[39m \u001B[43mBayesianModelSampling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1304\u001B[0m \u001B[43m        \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1305\u001B[0m \u001B[43m        \u001B[49m\u001B[43minclude_latents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_latents\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1306\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartial_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartial_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1309\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1311\u001B[0m \u001B[38;5;66;03m# Step 4: If evidence; do a rejection sampling\u001B[39;00m\n\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1313\u001B[0m     samples \u001B[38;5;241m=\u001B[39m BayesianModelSampling(model)\u001B[38;5;241m.\u001B[39mrejection_sample(\n\u001B[1;32m   1314\u001B[0m         size\u001B[38;5;241m=\u001B[39mn_samples,\n\u001B[1;32m   1315\u001B[0m         evidence\u001B[38;5;241m=\u001B[39m[(k, v) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m evidence\u001B[38;5;241m.\u001B[39mitems()],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1319\u001B[0m         partial_samples\u001B[38;5;241m=\u001B[39mpartial_samples,\n\u001B[1;32m   1320\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pgmpy/sampling/Sampling.py:114\u001B[0m, in \u001B[0;36mBayesianModelSampling.forward_sample\u001B[0;34m(self, size, include_latents, seed, show_progress, partial_samples, n_jobs)\u001B[0m\n\u001B[1;32m    110\u001B[0m unique, inverse \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(\n\u001B[1;32m    111\u001B[0m     evidence_values\u001B[38;5;241m.\u001B[39mT, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, return_inverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    112\u001B[0m )\n\u001B[1;32m    113\u001B[0m unique \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mtuple\u001B[39m(u) \u001B[38;5;28;01mfor\u001B[39;00m u \u001B[38;5;129;01min\u001B[39;00m unique]\n\u001B[0;32m--> 114\u001B[0m state_to_index, index_to_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpre_compute_reduce_maps\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvariable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate_combinations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munique\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    117\u001B[0m weight_index \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([state_to_index[u] \u001B[38;5;28;01mfor\u001B[39;00m u \u001B[38;5;129;01min\u001B[39;00m unique])[\n\u001B[1;32m    118\u001B[0m     inverse\n\u001B[1;32m    119\u001B[0m ]\n\u001B[1;32m    120\u001B[0m sampled[node] \u001B[38;5;241m=\u001B[39m sample_discrete_maps(\n\u001B[1;32m    121\u001B[0m     states, weight_index, index_to_weight, size\n\u001B[1;32m    122\u001B[0m )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pgmpy/sampling/base.py:153\u001B[0m, in \u001B[0;36mBayesianModelInference.pre_compute_reduce_maps\u001B[0;34m(self, variable, state_combinations, n_jobs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    152\u001B[0m     n_jobs \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mcpu_count()\n\u001B[0;32m--> 153\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m math\u001B[38;5;241m.\u001B[39mceil(\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstate_combinations\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m)\n\u001B[1;32m    155\u001B[0m weights_list \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, prefer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthreads\u001B[39m\u001B[38;5;124m\"\u001B[39m)(\n\u001B[1;32m    156\u001B[0m     delayed(BayesianModelInference\u001B[38;5;241m.\u001B[39m_reduce)(\n\u001B[1;32m    157\u001B[0m         variable_cpd,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m((\u001B[38;5;28mlen\u001B[39m(state_combinations) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m batch_size) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    166\u001B[0m )\n\u001B[1;32m    168\u001B[0m weights_list \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mlist\u001B[39m(itertools\u001B[38;5;241m.\u001B[39mchain(\u001B[38;5;241m*\u001B[39mweights_list)))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "a,b,c = run_exp(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T12:28:12.291979Z",
     "start_time": "2023-08-17T12:05:56.455461Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_comparison(a,b,c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tester.model.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(b, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the network structure\n",
    "model = BayesianNetwork([('A', 'B'), ('B', 'C')])\n",
    "\n",
    "# Create some data with missing values (using numpy.NaN)\n",
    "data = pd.DataFrame(data={'A': [1, 0, np.NaN, 1], 'B': [1, 1, 0, 0], 'C': [0, 1, 0, 0]})\n",
    "data = pd.DataFrame(data={'A': [np.NaN, np.NaN, np.NaN, 1, np.NaN], 'B': [np.NaN, np.NaN, np.NaN, 0, 1], 'C': [0, 1, 0, 0, 1]})\n",
    "# Use MaximumLikelihoodEstimator, and set complete_samples_only=False to handle missing data\n",
    "model.fit(data, estimator=MaximumLikelihoodEstimator, complete_samples_only=False)\n",
    "\n",
    "# Now the model has been fitted with the data, and missing values have been handled appropriately\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model.cpds[0], model.cpds[1\n",
    "], model.cpds[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
